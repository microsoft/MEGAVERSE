{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b0d19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a19a5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "026b1300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import List\n",
    "import spacy\n",
    "import openai\n",
    "import numpy as np\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from mega.data.load_datasets import load_xnli_dataset\n",
    "from mega.data.data_utils import choose_few_shot_examples\n",
    "from mega.prompting.instructions import INSTRUCTIONS\n",
    "from mega.prompting.prompting_utils import load_prompt_template\n",
    "from mega.utils.env_utils import load_openai_env_variables\n",
    "from mega.models.completion_models import (\n",
    "    get_model_pred,\n",
    "    gpt3x_completion,\n",
    "    substrate_llm_completion,\n",
    ")\n",
    "from mega.utils.substrate_llm import LLMClient\n",
    "from mega.prompting.prompting_utils import construct_prompt, construct_qa_prompt\n",
    "from tqdm.notebook import tqdm\n",
    "from evaluate import load\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ef56fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure that {env_name}.env file is present in the envs/ directory\n",
    "env_name = \"gpt4v2\"\n",
    "load_dotenv(\"envs/melange.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82cce2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-03-15-preview'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1992175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"dev-gpt-35-turbo\"\n",
    "pivot_lang = \"en\"\n",
    "tgt_lang = \"ta\"\n",
    "prompt_name = \"answer_given_context_and_question\"\n",
    "few_shot_k = 0\n",
    "dataset = \"indicqa\"\n",
    "short_contexts = False\n",
    "max_tokens = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc5117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\": model,\n",
    "    \"pivot_lang\": pivot_lang,\n",
    "    \"tgt_lang\": tgt_lang,\n",
    "    \"prompt_name\": prompt_name,\n",
    "    \"few_shot_k\": few_shot_k,\n",
    "    \"dataset\": dataset,\n",
    "    \"short_contexts\": short_contexts,\n",
    "    \"max_tokens\": max_tokens,\n",
    "}\n",
    "\n",
    "# wandb.init(project=\"GPT-4-eval\", entity=\"scai-msri\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645bc52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacySentenceTokenizer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"xx_ent_wiki_sm\")\n",
    "        self.nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "    def __call__(self, text: str) -> List[str]:\n",
    "        return list(map(lambda span: span.text, self.nlp(text).sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a7a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qa_dataset(dataset_name, lang, split, dataset_frac=1, translate_test=False):\n",
    "    if dataset_name == \"indicqa\":\n",
    "        if split != \"train\":\n",
    "            dataset = load_dataset(\"ai4bharat/IndicQA\", f\"indicqa.{lang}\")[split]\n",
    "        else:\n",
    "            dataset = load_dataset(\"squad\")[split]\n",
    "    elif dataset_name == \"xquad\":\n",
    "        if split != \"train\":\n",
    "            dataset = load_dataset(\"xquad\", f\"xquad.{lang}\")[split]\n",
    "        else:\n",
    "            dataset = load_dataset(\"squad\")[split]\n",
    "    elif dataset_name == \"tydiqa\":\n",
    "        dataset = load_dataset(\"tydiqa\", \"secondary_task\")[split]\n",
    "        dataset = dataset.map(\n",
    "            lambda example: {\"lang\": TYDIQA_LANG2CODES[example[\"id\"].split(\"-\")[0]]}\n",
    "        )\n",
    "        dataset = dataset.filter(lambda example: example[\"lang\"] == lang)\n",
    "    elif dataset_name == \"mlqa\":\n",
    "        if split == \"train\":\n",
    "            print(\"No Training Data for MLQA, switching to validation!\")\n",
    "            split = \"validation\"\n",
    "        if translate_test:\n",
    "            dataset_name = f\"mlqa-translate-test.{lang}\"\n",
    "        else:\n",
    "            dataset_name = f\"mlqa.{lang}.{lang}\"\n",
    "\n",
    "        dataset = load_dataset(\"mlqa\", dataset_name)[split]\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    N = len(dataset)\n",
    "    selector = np.arange(int(N * dataset_frac))\n",
    "    return dataset.select(selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a81d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_qa_dataset(dataset, lang=pivot_lang, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e4a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_qa_dataset(dataset, lang=tgt_lang, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5782b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if short_contexts:\n",
    "    sent_tokenizer = SpacySentenceTokenizer()\n",
    "\n",
    "    train_dataset = train_dataset.map(\n",
    "        lambda example: {\n",
    "            \"context\": [\n",
    "                sent\n",
    "                for sent in sent_tokenizer(example[\"context\"])\n",
    "                if example[\"answers\"][\"text\"][0] in sent\n",
    "            ][0]\n",
    "        },\n",
    "        num_proc=8,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98827b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = choose_few_shot_examples(\n",
    "    train_dataset, few_shot_k, selection_criteria=\"random\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b287a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS_DICT = {\n",
    "    \"answer_given_context_and_question\": \"\"\"{context}\n",
    "    Q: {question}\n",
    "\n",
    "    Referring to the passage above, the correct answer to the given question is:\n",
    "    {answer}\"\"\",\n",
    "    \"lang_instruct_answer_given_context_and_question\": \"\"\"{context}\n",
    "    Q: {question}\n",
    "\n",
    "    Referring to the passage above, the correct answer to the given question is? Please try to answer in {language} and ensure that the answer appears as it is in the passage.\n",
    "    A: {answer}\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a45e8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PROMPTS_DICT[prompt_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eb47ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an NLP assistant whose purpose is to solve reading comprehension problems. You will be provided questions on a set of passages and you will need to provide the answer as it appears in the passage. The answer should be in the same language as the question and the passage.\n"
     ]
    }
   ],
   "source": [
    "# Loading instruction for the task\n",
    "instruction = INSTRUCTIONS[\"xquad\"]\n",
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8367f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_metric = load(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fd344b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\n===\\n# OVERALL INSTRUCTIONS\\n===\\nYou are an NLP assistant whose purpose is to solve reading comprehension problems. You will be provided questions on a set of passages and you will need to provide the answer as it appears in the passage. The answer should be in the same language as the question and the passage.\\n\\n<|im_end|>\\n<|im_start|>user\\n1962 ல் பத்மஸ்ரீ விருது வழங்கப்படுவதற்கு கால் நூற்றாண்டுக்கு முன்பே இந்திய அரசால் அன்னை தெரேசா அடையாளங்காணப்பட்டுள்ளார். 1972-ல், பன்னாட்டு புரிந்துணர்வுக்கான ஜவகர்லால் நேரு விருது, 1980-ல் இந்தியாவின் உயரிய குடிமக்கள் விருதான பாரத ரத்னா உட்பட இந்திய உயர்விருதுகளை அடுத்த பத்தாண்டுகளில் பெற்றார். அவரது அதிகாரபூர்வ வாழ்க்கைச்சரித்திரம், இந்திய ஆட்சிப் பணியாளரான நவீன் சாவ்லாவால் எழுதப்பட்டு 1992இல் வெளியிடப்பட்டது. அன்னை தெரசாவைப் பற்றிய எல்லா இந்தியாரும் உயர்வாகப் பார்க்கவில்லை. கல்கத்தாவில் பிறந்து லண்டனில் வாழ்ந்து கொண்டிருக்கும் அவரது விமர்சகரான அரூப் ச்சேட்டர்ஜி அவர் வாழ்ந்த காலத்தில் கல்கத்தாவின் முக்கிய அங்கமாக இருக்கவில்லையெனக் குறிப்பிட்டுள்ளார். அன்னை தெரேசா தனது சொந்த ஊரான கல்கத்தாவின் புகழைக் குலைத்து விட்டதாகக் அவர்  குறை கூறியுள்ளார். பாரதிய ஜனதா கட்சி கிறிஸ்துவ தலித்துக்கள் விஷயத்தில், அவரோடு மோதிய போதிலும், அவரது மரணத்தின் போது அவரைப் புகழ்ந்து, இறுதி சடங்கிற்குத் தனது பதிளாளை அனுப்பியது. ஆனால் விஸ்வ ஹிந்து பரிஷத்தோ, அரசு மரியாதையுடன் கூடிய இறுதிச்சடங்கினை செய்யும் அரசாங்கத்தின் முடிவுக்கு எதிர்ப்புத் தெரிவித்தது. அதன் நிர்வாகி கிரிராஜ் கிஷோர், \"அவரது முதல் கடமை கிறிஸ்துவத்திற்கே இருந்தது\" என்றுக் கூறினார். பொது நல சேவை தற்செயலானது. மேலும் அவர் கிறிஸ்துவர்களுக்கு சாதகமானவரென்றும், இறப்பின் வாயிலிலிருப்போருக்கு இரகசிய திருமுழுக்கை மேற்கொள்ளுபவரென்றும் குற்றஞ்சாட்டினார். ஆனால் ஃப்ரண்ட் லைன் பத்திரிகையளித்த முதல் பக்கமரியாதையில் இக்குற்றச்சாட்டுகளை அப்பட்டமான தவறாக நிராகரித்துள்ளது. அவரது சேவையைப் பற்றிய கல்கத்தாவாசிகளின் எண்ணத்தில், எந்தத் தாக்கத்தையும் இவை விளைவித்துவிடவில்லை என்றும் கூறியிருக்கிறது. இப்புகழ்மாலையை சூட்டிய ஆசிரியர் அவரது தன்னலமற்ற சேவை செய்யும் சக்தியையும், தைரியத்தையும் புகழ்ந்தபோதிலும், பொது கூட்டங்களில் அவர் கருக்கலைப்பை எதிர்ப்பதையும், அதை அரசியல் நோக்கமில்லாததாகக் காட்டிக்கொள்வதையும் குறை கூறியுள்ளார். அண்மையில், இந்திய நாளேடான தி டெலிக்ராப், அவர் வறியவர்களின் துன்பத்தைப் போக்க ஏதேனும் செய்தாரா அல்லது உணர்வுபூர்வமாக நெறிகளைத் தூண்டும் நோக்கத்தோடு, நோயாளிகளையும் இறப்போரையும் பராமரித்து வந்தாடு நின்று விட்டாரா என்பதைக் குறித்து விசாரிக்கும்படி உரோமைக்கு வேண்டுகோள் விடுக்கப்பட்டுள்ளது என்று கூறியுள்ளது. செப்டம்பர் 1997 ல் இறுதிச்சடங்கிற்கு முன்னதாக ஒரு வார காலம் அன்னை தெரேசாவின் உடல் கொல்கத்தாவின் புனித தோமையார் ஆலயத்தில் பொதுமக்கள் பார்வைக்கு வைக்கப்பட்டிருந்தது. அனைத்து மத ஏழைகளுக்கும் அவர் ஆற்றிய தொண்டுக்குப் பரிகாரமாக, இந்திய அரசின் அரசு மரியாதையுடன் கூடிய இறுதிச்சடங்கு செய்யப்பட்டது. தெற்காசிய மற்றும் கிழக்காசிய சேவைகளுக்காக 1962-ல், பன்னாட்டுப் புரிந்துணர்தலுக்கான பிலிப்பைன்ஸின் ரமன் மக்சேசே விருதைப் பெற்றார். அயல்நாடுகளில் தாழ்த்தப்பட்ட ஏழைகளின் மீதான கருணை நிறைந்த கவனத்தையும், அதற்காகவே அவர் வழிநடத்திச் செல்லும் புதிய சபையையும் இவ்விருதின் தீர்வுக்குழுமம் அங்கீகரிக்கிறது என்று விருதில் குறிப்பிடப்பட்டிருந்தது. 1970களின் தொடக்கத்திற்குள் அன்னை தெரேசா அனைத்துலகாலும் அறியப்பட்டார். 1969இன் ஆவணப்படமான மேல்கம் முக்கேரிட்ஜ்-ன், சம்திங்க் பியுடிபுல் பார் காட் -ம், அதே தலைப்புடைய அவரது புத்தகமும் அவரது புகழுக்கு வித்திட்டவைகளில் முக்கியமானவை ஆகும். முக்கேரிட்ஜ் அந்நேரத்தில் ஒரு ஆன்மீக பயணத்தில் ஆழ்ந்திருந்தார். அச்செய்திப்படத்தின் படப்பிடிப்பின் போது மோசமான ஒளியமைப்பு சூழலில், குறிப்பாக இறப்பின் வாயிலிலிருப்போருக்கான இல்லங்களில் எடுக்கப்பட்ட காட்சிகள் பயன்பாட்டுக்கு உகந்தவையாக இல்லையென அவர் முதலில் நினைத்தாலும், இந்தியாவிலிருந்து திரும்பிய பின்னர் அக்காட்சிதொகுப்பு மிக நல்ல ஒளியமைப்புடன் வந்திருந்தது. அன்னை தெரேசாவிடமிருந்தே வந்த தெய்வீக ஒளியர்ப்புதம் இது என முக்கேரிட்ஜ் பறைசாற்றினார். அப்படப்பிடிப்புக் குழுவின் மற்றவர்கள் அது புதுவித அதிநுண்ணிய வகை கோடாக் படச்சுருளால் ஏற்பட்ட விளைவு என்றெண்ணினர். முக்கேரிட்ஜ் பின்னர் கத்தோலிக்கராகச் சமயம் மாறினார். இவ்வேளையில் கத்தோலிக்கர் உலகம் முழுவதும் அன்னை தெரேசாவைப் வெளிப்படையாய் புகழ ஆரம்பித்தனர். 1971-ல் திருத்தந்தை ஆறாம் பவுல், அமைதிக்கான முதல் திருத்தந்தை இருபத்திமூன்றாம் யோவான் பரிசை, அவரின் ஏழை எளியோருக்கான சேவையையும் கிறிஸ்துவ நெறியின் பறைசாற்றலையும், அமைதிக்கான முயற்சியையும் பாராட்டி அவருக்கு அளித்தார். அதன் பிறகு பேசெம் இன் டெர்ரிஸ் விருதைப் பெற்றார். தான் மரித்தநாளிலிருந்து அன்னை தெரேசா புனிதத்துவத்தினை நோக்கி வேகமாக முன்னேறித் தற்பொழுது முக்தி பேறினை எட்டியிருக்கிறார். அன்னை தெரேசா அரசாங்கங்களாலும், மக்கள் அமைப்புகளாலும் பெருமைப்படுத்தப்பட்டிருக்கிறார். ஆஸ்திரேலிய சமுதாயத்திற்கு மட்டுமல்லாது ஒட்டுமொத்த மனித குலத்துக்கும் செய்த சேவைக்காக, 1982-ல் அவர் ஆர்டர் ஆஃப் ஆஸ்திரேலியாவின் கௌரவ தோழர் என்ற விருதைப் பெற்றார். இங்கிலாந்தும், அமெரிக்காவும் அடுத்தடுத்து விருதுகள் வழங்கின.\\n    Q: அன்னை தெரசாவுக்கு எப்போது பத்மஸ்ரீ விருது வழங்கப்பட்டது?\\n\\n    Referring to the passage above, the correct answer to the given question is:\\n\\n<|im_end|>\\n<|im_start|>assistant'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example = test_dataset[132]\n",
    "\n",
    "prompt, label = construct_qa_prompt(\n",
    "    train_examples,\n",
    "    test_example,\n",
    "    train_prompt_template=prompt_template,\n",
    "    test_prompt_template=prompt_template,\n",
    "    chat_prompt=True,\n",
    "    instruction=instruction,\n",
    "    substrate_prompt=True,\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820350f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a22bbec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = gpt3x_completion(\n",
    "#     prompt,\n",
    "#     model,\n",
    "#     temperature=0,\n",
    "#     max_tokens=20\n",
    "# )\n",
    "llm_client = LLMClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "009abef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code EA79AJ9TY to authenticate.\n",
      "\n",
      "1962\n"
     ]
    }
   ],
   "source": [
    "pred = substrate_llm_completion(\n",
    "    llm_client, prompt, model_name=model, max_tokens=20, temperature=0\n",
    ")\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407bc6ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13e0413c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      "1962\n",
      "Label: 1962\n",
      "{'exact_match': 100.0, 'f1': 100.0}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prediction: {pred}\")\n",
    "print(f\"Label: {label}\")\n",
    "prediction = {\"prediction_text\": pred, \"id\": test_example[\"id\"]}\n",
    "reference = {}\n",
    "reference[\"answers\"] = test_example[\"answers\"]\n",
    "reference[\"id\"] = test_example[\"id\"]\n",
    "results = squad_metric.compute(predictions=[prediction], references=[reference])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc555f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b8b957c5904b65adcf21684808811c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/anaconda/envs/mega/lib/python3.9/site-packages/backoff/_sync.py:105\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     ret \u001b[39m=\u001b[39m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    106\u001b[0m \u001b[39mexcept\u001b[39;00m exception \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/MultilingualBlanketEval/mega/models/completion_models.py:54\u001b[0m, in \u001b[0;36msubstrate_llm_completion\u001b[0;34m(llm_client, prompt, model_name, **model_params)\u001b[0m\n\u001b[1;32m     53\u001b[0m response \u001b[39m=\u001b[39m llm_client\u001b[39m.\u001b[39msend_request(model_name, request_data)\n\u001b[0;32m---> 54\u001b[0m text_result \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39;49m\u001b[39mchoices\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     55\u001b[0m text_result \u001b[39m=\u001b[39m text_result\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m<|im_end|>\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'choices'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, test_example \u001b[39min\u001b[39;00m pbar:    \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     prompt, label \u001b[39m=\u001b[39m construct_qa_prompt(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m         train_examples,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m         test_example,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m         substrate_prompt\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     pred \u001b[39m=\u001b[39m substrate_llm_completion(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     llm_client, prompt, model_name\u001b[39m=\u001b[39;49mmodel, max_tokens\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m# print(prompt)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# pred = gpt3x_completion(\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m#     prompt,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m#     max_tokens=max_tokens\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m# )\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/home/t-sahuja/MultilingualBlanketEval/MEGANotebooks/MEGAQAGPT-4.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     prediction \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mprediction_text\u001b[39m\u001b[39m\"\u001b[39m: pred, \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m: test_example[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m]}\n",
      "File \u001b[0;32m/anaconda/envs/mega/lib/python3.9/site-packages/backoff/_sync.py:127\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    124\u001b[0m     _call_handlers(on_backoff, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdetails, wait\u001b[39m=\u001b[39mseconds,\n\u001b[1;32m    125\u001b[0m                    exception\u001b[39m=\u001b[39me)\n\u001b[0;32m--> 127\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n\u001b[1;32m    128\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     _call_handlers(on_success, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdetails)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f1_sum = 0\n",
    "em_sum = 0\n",
    "avg_em = 0\n",
    "avg_f1 = 0\n",
    "\n",
    "run_details = {\"num_calls\": 0}\n",
    "\n",
    "pbar = tqdm(enumerate(test_dataset))\n",
    "\n",
    "for i, test_example in pbar:\n",
    "    prompt, label = construct_qa_prompt(\n",
    "        train_examples,\n",
    "        test_example,\n",
    "        train_prompt_template=prompt_template,\n",
    "        test_prompt_template=prompt_template,\n",
    "        chat_prompt=True,\n",
    "        instruction=instruction,\n",
    "        substrate_prompt=True,\n",
    "    )\n",
    "    pred = substrate_llm_completion(\n",
    "        llm_client, prompt, model_name=model, max_tokens=20, temperature=0\n",
    "    )\n",
    "    # print(prompt)\n",
    "    # pred = gpt3x_completion(\n",
    "    #     prompt,\n",
    "    #     model,\n",
    "    #     temperature=0,\n",
    "    #     run_details=run_details,\n",
    "    #     max_tokens=max_tokens\n",
    "    # )\n",
    "    prediction = {\"prediction_text\": pred, \"id\": test_example[\"id\"]}\n",
    "    reference = {}\n",
    "    reference[\"answers\"] = test_example[\"answers\"]\n",
    "    reference[\"id\"] = test_example[\"id\"]\n",
    "    results = squad_metric.compute(predictions=[prediction], references=[reference])\n",
    "    f1_sum += results[\"f1\"]\n",
    "    em_sum += results[\"exact_match\"]\n",
    "\n",
    "    avg_f1 = f1_sum / (i + 1)\n",
    "    avg_em = em_sum / (i + 1)\n",
    "\n",
    "    # wandb.log({\"f1\": avg_f1, \"em\": avg_em}, step = i + 1)\n",
    "    # wandb.log(run_details, step = i + 1)\n",
    "    pbar.set_description(f\"em: {avg_em} f1: {avg_f1}\")\n",
    "    time.sleep(1 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IProgress"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
