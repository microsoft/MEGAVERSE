{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "160ff6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02807a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "import openai\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from mega.data.data_utils import choose_few_shot_examples\n",
    "from mega.prompting.instructions import INSTRUCTIONS\n",
    "from mega.prompting.prompting_utils import load_prompt_template\n",
    "# from mega.utils.env_utils import load_env\n",
    "from mega.models.completion_models import get_model_pred, gpt3x_completion, gemini_completion\n",
    "from mega.prompting.prompting_utils import construct_prompt, construct_cmxnli_prompt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdecbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make sure that {env_name}.env file is present in the envs/ directory\n",
    "# env_name = \"melange\"\n",
    "# load_env(env_name=env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f254c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://gpttesting1.openai.azure.com/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5508b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gemini-pro\"\n",
    "prompt_name = \"GPT-3 style\"\n",
    "few_shot_k = 8\n",
    "lang = \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b925ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the extracted JSON file\n",
    "with open(\"gluecosdata/nli/all.json\", \"r\") as json_file:\n",
    "    # Load the JSON data\n",
    "    data = json.load(json_file)\n",
    "\n",
    "    # Convert the JSON data to a pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Read the text file with test set IDs\n",
    "    with open(\"gluecosdata/nli/test_ids.txt\", \"r\") as test_ids_file:\n",
    "        # Extract the IDs as a list of strings\n",
    "        test_ids = [int(line.strip()) for line in test_ids_file]\n",
    "\n",
    "        # Split the DataFrame into train and test subsets based on the IDs\n",
    "        train_df = df[~df['ID'].isin(test_ids)].reset_index(drop=True)\n",
    "        train_df\n",
    "        test_df = df[df['ID'].isin(test_ids)].reset_index(drop=True)\n",
    "        \n",
    "        # Convert the train and test DataFrames to Dataset objects\n",
    "        train_dataset = Dataset.from_pandas(train_df)\n",
    "        test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "        # Create a DatasetDict object with train and test datasets\n",
    "        dataset_dict = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "\n",
    "    # Close the test IDs file\n",
    "    test_ids_file.close()\n",
    "\n",
    "# Close the JSON file\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a754c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 0,\n",
       " 'Premise ID': '465',\n",
       " 'Premise': 'FATHER\\nMain wapis hospital jaa raha hun .\\nRAHUL\\nMaa , main dieting pe hun , mere liye green tea please .\\nMOTHER\\nHaan , okay beta .\\nRAHUL\\nEk aur baat .. (he pulls something out of his pocket) Ye aapke liye ..\\nMOTHER\\nOh .. You are just .. Mera perfect baccha .\\n',\n",
       " 'Hypothesis': 'Dady wapas hospital ja rahe hain',\n",
       " 'Label': 'entailed'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a01cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FATHER\\nMain wapis hospital jaa raha hun .\\nRAHUL\\nMaa , main dieting pe hun , mere liye green tea please .\\nMOTHER\\nHaan , okay beta .\\nRAHUL\\nEk aur baat .. (he pulls something out of his pocket) Ye aapke liye ..\\nMOTHER\\nOh .. You are just .. Mera perfect baccha .\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"Premise\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "954afeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"{premise} Question: {hypothesis} True or False? ||| {label}\"\"\"\n",
    "verbalizer = {\"entailed\": \"True\", \"contradiction\": \"False\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "390d4bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an NLP assistant whose purpose is to solve Natural Language Inference (NLI) problems. NLI is the task of determining the inference relation between two (short, ordered) texts: entailment, contradiction, or neutral. Answer as concisely as possible in the same format as the examples below:\n"
     ]
    }
   ],
   "source": [
    "# Loading instruction for the task\n",
    "instruction = INSTRUCTIONS[\"xnli\"]\n",
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a49b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting few-shot examples\n",
    "train_examples = choose_few_shot_examples(\n",
    "    train_dataset, few_shot_k, selection_criteria=\"random\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "959a3916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MOTHER\\nFamily photo ke liye tumhari jacket nikali hai ...\\nFATHER\\nAh .. Thanks .\\nFATHER\\nMain gaadi zara garage deke aata hun , Sashi kahaan hain ?\\nMOTHER\\nRahul ussey property dikhane le gaya hai .\\n Question: Father bas thodi der ke liye gaadi garage le ja rahe hain.  True or False? |||\\nFalse\\nDADDY\\nI d h a r r a k h t e hain . Ashirwad rahega .\\nVIKRAM\\nHogaya tera bawle , toh Daddyji ki dawai le aa .\\nPRADEEP\\nOkok .\\nPRADEEP\\nTitli ! Chal sang mere .\\nNEELU\\nYe atachy bistar pe rakh doge .\\n Question: VIKRAM daddyji ki dawaai laane ja raha hai True or False? |||\\nFalse\\nISHAAN\\nJeet gaye .. Ye lo saalon .. Ind eaah !! Ind eaah !!... Jeet gaye bhai jeet gaye !! Indiaaaah !!\\nISHAAN\\nBaka .. Bahut miss kiya tere ko .\\nOMI\\nJaanta hun ..\\nISHAAN\\nOye .. Oye .. Oye !! Bhajji ka hat trick dekha ?? Mindblowing yaar !!\\nBOY\\nEk season ball aur ek set keeping gloves .. jaldi please .. hamara match shuru hone wala hai ..\\n Question: ISHAAN ne OMI ko bahut miss kiya True or False? |||\\nTrue\\nYADAV\\nAe ... kya ho raha hai ? Kisne kaha yahaan aane ...\\nDEVI\\nApna samaan lene aayi hoon . Aur yeh aisa gandi baaton waala phone dobara mat karna ... sadak pe dauda ke maarenge !\\nYADAV\\nTopper ladka tha apna ... sharam nahin aayi ?\\nDEVI\\nJo bhi kiya donon ne kiya .\\nYADAV\\nMara toh wo akela na !\\n Question: DEVI ne YADAV ko sadak pe dauda ke maarne ki dhamki dee.  True or False? |||\\nTrue\\nPRADEEP\\nAC Petrol .\\nVIKRAM\\nJhumke bade pyaare pehne h a i n laundiya ne .\\nPRADEEP\\nNoida waale south ko bhi peeche chor re hain .\\nVIKRAM\\nTeri bhabhi pe khoob khapenge .\\nPRADEEP\\nBhabhi koi apni south delhi se kam hai .\\nPRADEEP\\nBas karo bai half time ho gaya .\\n Question: Laundiya ne jhumke acche pehne hain True or False? |||\\nTrue\\nSHAHID\\nHumara case strong hai .\\nMARIAM\\nHum jeetenge ?\\nSHAHID\\nJeetna Chahiye .\\nMARIAM\\nKitna time lagega ?\\nSHAHID\\nmahine ya ussey thoda zyaada .\\nMARIAM\\nPerfect .\\nSHAHID\\nKoi Jaldi hai ?\\nMARIAM\\nHaan property sell karke Assam jaana hai .\\nSHAHID\\nKyon ?\\nMARIAM\\nEk school start karoongi .\\nSHAHID\\nWoh aap yahaan bhi kar sakti hain .\\nMARIAM\\nAap chahte hain main yahan rukoon , kyon ?\\nSHAHID\\nKyonki yeh ..\\nMARIAM\\nShayad , ruk bhi jaaoon .\\nSHAHID\\nAs a lawyer mujhe sab pata hona chahiye aapke baare mein .\\nMARIAM\\nAchcha .\\nSHAHID\\nAre you ?\\nMARIAM\\nNo . Mujhe chalna chahiye .\\nSHAHID\\nOk .\\nSHAHID\\nDate milte hi inform karoonga .\\n Question: MARIAM ko property sell karke Assam jaana hai True or False? |||\\nTrue\\nOMI\\nJai shri Krishna mama .\\nOMI:\\nHaan .. Station hi ja raha tha .. Kyun ? Ji .. Sabarmati express .. Haan S6 , ji mujhe pucca pata hai , S6 hi hai .. Kyun ?\\nOMI:\\nAchha .. Theek hai .. aata hun\\nOMI\\nGhuma lo .. Party office\\n Question: OMI station ja raha tha True or False? |||\\nTrue\\nNEELU\\nKya hua ?\\nTITLI\\nEk mint . Kaam hai ek aur .\\nTITLI\\nCall kitte ki ?\\nPCO GUY\\nDo rupaye .\\nTITLI\\nHaanji mandi chowki ? Khabar deni hai ek . Jaipur highway , hindon chowk pe dakaiti ka plan hai aaj . Ek karor ki . Do bande gaadi se churayenge , DL-1512 number . Rok sako toh rok lo .\\nTITLI\\nK a r n a j a r o o r i h a i . Roka nahi u n k o , seedha mere tere peeche aayenge .\\n Question: Ek crore ki robbery 3 log karenge True or False? |||\\nFalse\\nSHYAMA\\nKaadha pee lo didi . Doctor sahab ne bola hai ...\\nSHYAMA\\nKaadha pee lo .\\nPAKHI\\nMain pee loongi , mez par rakh do .\\nSHYAMA\\nAbhi peeyo , hamaare saamne .\\nPAKHI\\nBola na mez par rakh do , pee loongi ...\\nPAKHI\\nMujhe maaf kar do .\\n Question: PAKHI ne SHYAMA se maafi maangi True or False? |||\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example = test_dataset[0]\n",
    "\n",
    "prompt, label = construct_cmxnli_prompt(\n",
    "    train_examples,\n",
    "    test_dataset[0],\n",
    "    train_prompt_template=template,\n",
    "    test_prompt_template=template,\n",
    "    chat_prompt=False,\n",
    "    instruction=instruction,\n",
    "    verbalizer=verbalizer,\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65b67c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: True\n",
      "Label: True\n",
      "Match: 1.0\n"
     ]
    }
   ],
   "source": [
    "prediction = gemini_completion(\n",
    "    prompt,\n",
    "    model,\n",
    "    lang,\n",
    "    temperature=0,\n",
    "    max_tokens=10\n",
    ")\n",
    "match = float(prediction.startswith(label))\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Match: {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7adde71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 376/448 [20:52<03:12,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 448/448 [25:34<00:00,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8080357142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "matches = []\n",
    "preds = []\n",
    "labels = []\n",
    "for test_example in tqdm(test_dataset):\n",
    "    prompt, label = construct_cmxnli_prompt(\n",
    "        train_examples,\n",
    "        test_example,\n",
    "        train_prompt_template=template,\n",
    "        test_prompt_template=template,\n",
    "        chat_prompt=False,\n",
    "        instruction=instruction,\n",
    "        verbalizer=verbalizer,\n",
    "    )\n",
    "    prediction = gemini_completion(\n",
    "        prompt,\n",
    "        model,\n",
    "        lang,\n",
    "        temperature=0,\n",
    "        max_tokens=10\n",
    "    )\n",
    "    time.sleep(1/2)\n",
    "    match = float(prediction.startswith(label))\n",
    "    preds.append(prediction)\n",
    "    labels.append(label)\n",
    "    matches.append(match)\n",
    "\n",
    "print(f\"Accuracy: {np.mean(matches)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33bd6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"results/gluecos_nli/gemini-pro/english-hindi/PivotLang_{lang}_PromptName_{prompt_name}_FewShotK_{few_shot_k}\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0335e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (pred, label, match) in enumerate(zip(preds, labels, matches)):\n",
    "    results = {\n",
    "        \"idx\" : idx,\n",
    "        \"prediction\" : pred,\n",
    "        \"label\" : label,\n",
    "        \"match\" : match\n",
    "    }\n",
    "    with open(os.path.join(output_dir, \"preds.json\"), \"a\") as f:   \n",
    "        f.write(json.dumps(results, ensure_ascii=False)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "941d1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, \"results.json\"), \"w\") as f:\n",
    "    results = {\n",
    "        \"env\": \"melange\",\n",
    "        \"dataset\": \"glucose_nli\",\n",
    "        \"pivot_lang\": \"en-hi\",\n",
    "        \"tgt_lang\": \"en-hi\",\n",
    "        \"pivot_prompt_name\": prompt_name,\n",
    "        \"tgt_prompt_name\": prompt_name,\n",
    "        \"few_shot_k\": few_shot_k,\n",
    "        \"few_shot_selection\": \"random\",\n",
    "        \"seed\": 42,\n",
    "        \"model\": \"gemini-pro\",\n",
    "        \"model_type\": \"completion\",\n",
    "        \"save_dir\": \"results\",\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 1,\n",
    "        \"max_tokens\": 10,\n",
    "        \"metrics\" :{\n",
    "            \"accuracy\" : np.mean(matches)\n",
    "        }\n",
    "    }\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3cf3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
